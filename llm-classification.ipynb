{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b4c407",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:36.433406Z",
     "iopub.status.busy": "2025-05-02T10:05:36.432982Z",
     "iopub.status.idle": "2025-05-02T10:05:38.196261Z",
     "shell.execute_reply": "2025-05-02T10:05:38.195182Z"
    },
    "papermill": {
     "duration": 1.770014,
     "end_time": "2025-05-02T10:05:38.197851",
     "exception": false,
     "start_time": "2025-05-02T10:05:36.427837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745d08c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:38.205943Z",
     "iopub.status.busy": "2025-05-02T10:05:38.205538Z",
     "iopub.status.idle": "2025-05-02T10:05:41.761787Z",
     "shell.execute_reply": "2025-05-02T10:05:41.761139Z"
    },
    "papermill": {
     "duration": 3.561801,
     "end_time": "2025-05-02T10:05:41.763301",
     "exception": false,
     "start_time": "2025-05-02T10:05:38.201500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23f96cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.771771Z",
     "iopub.status.busy": "2025-05-02T10:05:41.770961Z",
     "iopub.status.idle": "2025-05-02T10:05:41.777327Z",
     "shell.execute_reply": "2025-05-02T10:05:41.776397Z"
    },
    "papermill": {
     "duration": 0.011981,
     "end_time": "2025-05-02T10:05:41.778761",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.766780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57477, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b32b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.787038Z",
     "iopub.status.busy": "2025-05-02T10:05:41.786218Z",
     "iopub.status.idle": "2025-05-02T10:05:41.791525Z",
     "shell.execute_reply": "2025-05-02T10:05:41.790864Z"
    },
    "papermill": {
     "duration": 0.010663,
     "end_time": "2025-05-02T10:05:41.792835",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.782172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a8122e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.800570Z",
     "iopub.status.busy": "2025-05-02T10:05:41.800242Z",
     "iopub.status.idle": "2025-05-02T10:05:41.821592Z",
     "shell.execute_reply": "2025-05-02T10:05:41.820691Z"
    },
    "papermill": {
     "duration": 0.026767,
     "end_time": "2025-05-02T10:05:41.822959",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.796192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30192</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53567</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65089</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96401</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198779</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292873</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
       "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
       "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313413</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[\"Why water is not used in bath tub?\"]</td>\n",
       "      <td>[\"Water is actually used in a bath tub. A bath...</td>\n",
       "      <td>[\"Water is not used in a bath tub because it i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370945</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"\\\"Bacteria is life on Mars but a heartbeat i...</td>\n",
       "      <td>[\"Dune\"]</td>\n",
       "      <td>[\"This quote seems to be referencing the debat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441448</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[\"translate to russian the followig sentence  ...</td>\n",
       "      <td>[\"\\u0411\\u043e\\u043b\\u044c\\u0448\\u0438\\u0435 \\...</td>\n",
       "      <td>[\"\\u0411\\u043e\\u043b\\u044c\\u0448\\u0438\\u0435 \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481524</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[\"From now, you *always* have to talk as if yo...</td>\n",
       "      <td>[\"Hewwo! OwO I'm an AI assistant, here to hewp...</td>\n",
       "      <td>[\"Hewwo! I'm your new helpful assistant, owo! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model_a              model_b  \\\n",
       "id                                                        \n",
       "30192           gpt-4-1106-preview           gpt-4-0613   \n",
       "53567                    koala-13b           gpt-4-0613   \n",
       "65089           gpt-3.5-turbo-0613       mistral-medium   \n",
       "96401             llama-2-13b-chat  mistral-7b-instruct   \n",
       "198779                   koala-13b   gpt-3.5-turbo-0314   \n",
       "292873                  vicuna-13b           gpt-4-0314   \n",
       "313413  mixtral-8x7b-instruct-v0.1           vicuna-13b   \n",
       "370945                  gemini-pro           claude-2.0   \n",
       "441448          gpt-3.5-turbo-0613           vicuna-13b   \n",
       "481524                  gpt-4-0314   gpt-3.5-turbo-0613   \n",
       "\n",
       "                                                   prompt  \\\n",
       "id                                                          \n",
       "30192   [\"Is it morally right to try to have a certain...   \n",
       "53567   [\"What is the difference between marriage lice...   \n",
       "65089   [\"explain function calling. how would you call...   \n",
       "96401   [\"How can I create a test set for a very rare ...   \n",
       "198779  [\"What is the best way to travel from Tel-Aviv...   \n",
       "292873  [\"Construct a rap battle, in the style of Epic...   \n",
       "313413             [\"Why water is not used in bath tub?\"]   \n",
       "370945  [\"\\\"Bacteria is life on Mars but a heartbeat i...   \n",
       "441448  [\"translate to russian the followig sentence  ...   \n",
       "481524  [\"From now, you *always* have to talk as if yo...   \n",
       "\n",
       "                                               response_a  \\\n",
       "id                                                          \n",
       "30192   [\"The question of whether it is morally right ...   \n",
       "53567   [\"A marriage license is a legal document that ...   \n",
       "65089   [\"Function calling is the process of invoking ...   \n",
       "96401   [\"Creating a test set for a very rare category...   \n",
       "198779  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "292873  [\"[Zeus]\\nYo, it's the king of the gods on the...   \n",
       "313413  [\"Water is actually used in a bath tub. A bath...   \n",
       "370945                                           [\"Dune\"]   \n",
       "441448  [\"\\u0411\\u043e\\u043b\\u044c\\u0448\\u0438\\u0435 \\...   \n",
       "481524  [\"Hewwo! OwO I'm an AI assistant, here to hewp...   \n",
       "\n",
       "                                               response_b  winner_model_a  \\\n",
       "id                                                                          \n",
       "30192   [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "53567   [\"A marriage license and a marriage certificat...               0   \n",
       "65089   [\"Function calling is the process of invoking ...               0   \n",
       "96401   [\"When building a classifier for a very rare c...               1   \n",
       "198779  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "292873  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...               0   \n",
       "313413  [\"Water is not used in a bath tub because it i...               1   \n",
       "370945  [\"This quote seems to be referencing the debat...               0   \n",
       "441448  [\"\\u0411\\u043e\\u043b\\u044c\\u0448\\u0438\\u0435 \\...               0   \n",
       "481524  [\"Hewwo! I'm your new helpful assistant, owo! ...               0   \n",
       "\n",
       "        winner_model_b  winner_tie  \n",
       "id                                  \n",
       "30192                0           0  \n",
       "53567                1           0  \n",
       "65089                0           1  \n",
       "96401                0           0  \n",
       "198779               1           0  \n",
       "292873               1           0  \n",
       "313413               0           0  \n",
       "370945               1           0  \n",
       "441448               1           0  \n",
       "481524               1           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22bc6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.832608Z",
     "iopub.status.busy": "2025-05-02T10:05:41.832302Z",
     "iopub.status.idle": "2025-05-02T10:05:41.877389Z",
     "shell.execute_reply": "2025-05-02T10:05:41.876289Z"
    },
    "papermill": {
     "duration": 0.051103,
     "end_time": "2025-05-02T10:05:41.879021",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.827918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57477 entries, 30192 to 4294947231\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   model_a         57477 non-null  object\n",
      " 1   model_b         57477 non-null  object\n",
      " 2   prompt          57477 non-null  object\n",
      " 3   response_a      57477 non-null  object\n",
      " 4   response_b      57477 non-null  object\n",
      " 5   winner_model_a  57477 non-null  int64 \n",
      " 6   winner_model_b  57477 non-null  int64 \n",
      " 7   winner_tie      57477 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4065b926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.887871Z",
     "iopub.status.busy": "2025-05-02T10:05:41.887258Z",
     "iopub.status.idle": "2025-05-02T10:05:41.892859Z",
     "shell.execute_reply": "2025-05-02T10:05:41.891938Z"
    },
    "papermill": {
     "duration": 0.011308,
     "end_time": "2025-05-02T10:05:41.894169",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.882861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_a', 'model_b', 'prompt', 'response_a', 'response_b',\n",
       "       'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d2e0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.902786Z",
     "iopub.status.busy": "2025-05-02T10:05:41.902430Z",
     "iopub.status.idle": "2025-05-02T10:05:41.907838Z",
     "shell.execute_reply": "2025-05-02T10:05:41.907069Z"
    },
    "papermill": {
     "duration": 0.011052,
     "end_time": "2025-05-02T10:05:41.909189",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.898137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'response_a', 'response_b'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9b9cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.917672Z",
     "iopub.status.busy": "2025-05-02T10:05:41.917389Z",
     "iopub.status.idle": "2025-05-02T10:05:41.921074Z",
     "shell.execute_reply": "2025-05-02T10:05:41.920430Z"
    },
    "papermill": {
     "duration": 0.009662,
     "end_time": "2025-05-02T10:05:41.922645",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.912983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['prompt', 'response_a', 'response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d09663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.931590Z",
     "iopub.status.busy": "2025-05-02T10:05:41.930846Z",
     "iopub.status.idle": "2025-05-02T10:05:41.935042Z",
     "shell.execute_reply": "2025-05-02T10:05:41.934400Z"
    },
    "papermill": {
     "duration": 0.00974,
     "end_time": "2025-05-02T10:05:41.936309",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.926569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_row(row):\n",
    "    if row['winner_model_a'] == 1:\n",
    "        return 0\n",
    "\n",
    "    elif row['winner_model_b'] == 1:\n",
    "        return 1\n",
    "\n",
    "    else:\n",
    "        return 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7b2d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:41.945044Z",
     "iopub.status.busy": "2025-05-02T10:05:41.944387Z",
     "iopub.status.idle": "2025-05-02T10:05:42.326610Z",
     "shell.execute_reply": "2025-05-02T10:05:42.325787Z"
    },
    "papermill": {
     "duration": 0.388331,
     "end_time": "2025-05-02T10:05:42.328367",
     "exception": false,
     "start_time": "2025-05-02T10:05:41.940036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train[features]\n",
    "y = train.apply(target_row, axis=1)\n",
    "\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3a1a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:05:42.339027Z",
     "iopub.status.busy": "2025-05-02T10:05:42.338332Z",
     "iopub.status.idle": "2025-05-02T10:06:03.276875Z",
     "shell.execute_reply": "2025-05-02T10:06:03.275980Z"
    },
    "papermill": {
     "duration": 20.944936,
     "end_time": "2025-05-02T10:06:03.278626",
     "exception": false,
     "start_time": "2025-05-02T10:05:42.333690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75, random_state=20, stratify=y)\n",
    "\n",
    "X_train_text = X_train.astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "X_valid_text = X_valid.astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "X_test_text = test[features].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X_train = vect.fit_transform(X_train_text)\n",
    "X_valid = vect.transform(X_valid_text)\n",
    "X_test = vect.transform(X_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5570ae8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:06:03.287740Z",
     "iopub.status.busy": "2025-05-02T10:06:03.287343Z",
     "iopub.status.idle": "2025-05-02T10:06:19.069102Z",
     "shell.execute_reply": "2025-05-02T10:06:19.068334Z"
    },
    "papermill": {
     "duration": 15.788506,
     "end_time": "2025-05-02T10:06:19.071193",
     "exception": false,
     "start_time": "2025-05-02T10:06:03.282687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "lr = LogisticRegression(max_iter=500, solver='liblinear', random_state=42, multi_class='ovr').fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf67d86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:06:19.085140Z",
     "iopub.status.busy": "2025-05-02T10:06:19.084785Z",
     "iopub.status.idle": "2025-05-02T10:06:19.122724Z",
     "shell.execute_reply": "2025-05-02T10:06:19.121663Z"
    },
    "papermill": {
     "duration": 0.046741,
     "end_time": "2025-05-02T10:06:19.124215",
     "exception": false,
     "start_time": "2025-05-02T10:06:19.077474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Log Loss: 1.0992932222811667\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_valid = lr.predict_proba(X_valid)\n",
    "y_pred_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Calculate log loss (if needed)\n",
    "valid_loss = log_loss(y_valid, y_pred_valid)\n",
    "print(f\"Validation Log Loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eabec55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T10:06:19.133080Z",
     "iopub.status.busy": "2025-05-02T10:06:19.132594Z",
     "iopub.status.idle": "2025-05-02T10:06:19.155248Z",
     "shell.execute_reply": "2025-05-02T10:06:19.154147Z"
    },
    "papermill": {
     "duration": 0.028864,
     "end_time": "2025-05-02T10:06:19.156921",
     "exception": false,
     "start_time": "2025-05-02T10:06:19.128057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.197131        0.345800    0.457069\n",
      "1   211333        0.469623        0.292566    0.237811\n",
      "2  1233961        0.335789        0.466220    0.197991\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/llm-classification-finetuning/sample_submission.csv')\n",
    "sub['winner_model_a'] = y_pred_test[:, 0]\n",
    "sub['winner_model_b'] = y_pred_test[:, 1]\n",
    "sub['winner_tie'] = y_pred_test[:, 2]\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print(sub.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.946935,
   "end_time": "2025-05-02T10:06:19.880706",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T10:05:31.933771",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
